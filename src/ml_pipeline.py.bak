import os
import time
from tqdm import tqdm
from typing import list, tuple
try:
  from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, GenerationConfig
  import torch
except Exception:
    AutoTokenizer = None
    AutoModelForCausalLM = None
    pipeline = None
    GenerationConfig = None
    torch = None

try:
   from huggingface_hub import inferenceClient
except Exception:
    InferenceClient = None

try:
   from sentence_transformers import SentenceTransformer
   from chromadb
   from chromadb.utils import embedding_functions
except Exception:
    SentenceTransformer = None
    chromadb = None
    embedding_functions = None

from utils import
from config import

# ---------------------------
# PROMPTS (prompt engineering)
# ---------------------------
BASE_PROMPT = """You are a fraud detection assistant. Answer in exactly three lines:
LABEL: FRAUD or NOT_FRAUD
CONFIDENCE: decimal between 0 and 1
REASON: short explanation sentence.

Transaction:
{txn_text}

Now provide the answer adhering to the format exactly.
"""

FEW_SHOT_PROMPT = """You are a fraud detection assistant. Answer in exactly three lines:
LABEL: FRAUD or NOT_FRAUD
CONFIDENCE: decimal between 0 and 1
REASON: short explanation sentence.

Example 1:
Transaction: Transaction TID: 100 — Amount: $5 — Device: usual
LABEL: NOT_FRAUD
CONFIDENCE: 0.05
REASON: Small routine purchase.

Example 2:
Transaction: Transaction TID: 101 — Amount: $2000 — Device: new
LABEL: FRAUD
CONFIDENCE: 0.95
REASON: Very large unusual purchase on a new device.

Now classify:
Transaction:
{txn_text}

Answer now.
"""

